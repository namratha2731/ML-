{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0ec812e-4316-4d8e-8a90-71b7d921b121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Perceptron:  {'penalty': 'l2', 'max_iter': 1000, 'alpha': 0.0001}\n",
      "Best Parameters for MLP:  {'solver': 'sgd', 'learning_rate': 'constant', 'hidden_layer_sizes': (100,), 'alpha': 0.0001, 'activation': 'tanh'}\n",
      "Perceptron Accuracy:  0.047407407407407405\n",
      "MLP Accuracy:  0.034074074074074076\n"
     ]
    }
   ],
   "source": [
    "#A2\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"D:\\\\NEHA_docs\\\\Amrita__Docs\\\\5th SEM\\\\ML\\\\PROJECT\\\\DCT_withoutduplicate_data for project.csv\")\n",
    "\n",
    "# Assume the last column is the target, and the rest are features\n",
    "X = df.iloc[:, :-1]  # Features\n",
    "y = df.iloc[:, -1]   # Target\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# A2: Hyperparameter Tuning using RandomizedSearchCV for Perceptron\n",
    "perceptron = Perceptron()\n",
    "param_grid_perceptron = {\n",
    "    'penalty': ['l2', 'elasticnet'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'max_iter': [1000, 2000, 3000]\n",
    "}\n",
    "random_search_perceptron = RandomizedSearchCV(perceptron, param_grid_perceptron, n_iter=10, cv=5, random_state=42)\n",
    "random_search_perceptron.fit(X_train, y_train)\n",
    "print(\"Best Parameters for Perceptron: \", random_search_perceptron.best_params_)\n",
    "\n",
    "# A2: Hyperparameter Tuning using RandomizedSearchCV for MLP\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "param_grid_mlp = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "random_search_mlp = RandomizedSearchCV(mlp, param_grid_mlp, n_iter=10, cv=5, random_state=42)\n",
    "random_search_mlp.fit(X_train, y_train)\n",
    "print(\"Best Parameters for MLP: \", random_search_mlp.best_params_)\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "best_perceptron = random_search_perceptron.best_estimator_\n",
    "best_mlp = random_search_mlp.best_estimator_\n",
    "\n",
    "y_pred_perceptron = best_perceptron.predict(X_test)\n",
    "y_pred_mlp = best_mlp.predict(X_test)\n",
    "\n",
    "print(\"Perceptron Accuracy: \", accuracy_score(y_test, y_pred_perceptron))\n",
    "print(\"MLP Accuracy: \", accuracy_score(y_test, y_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62aef3bb-4ef3-48fd-a72f-42f8a3ecacc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Classifier  Accuracy  Precision    Recall  F1-Score\n",
      "0            SVM  0.080000   0.078162  0.080000  0.044312\n",
      "1  Decision Tree  0.629630   0.644389  0.629630  0.624368\n",
      "2  Random Forest  0.882963   0.882687  0.882963  0.878677\n",
      "3       AdaBoost  0.077037   0.024804  0.077037  0.029584\n",
      "4    Naive Bayes  0.520000   0.624187  0.520000  0.535893\n"
     ]
    }
   ],
   "source": [
    "#A3\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# Train each classifier and compute the performance metrics\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Append the performance metrics for each classifier to the list\n",
    "    results_list.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted'),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted'),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred, average='weighted')\n",
    "    })\n",
    "\n",
    "# Convert the list of results into a DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15a9c47a-c1fd-4148-ae4c-c5307afda632",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Example dataset (replace with your actual dataset)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Assume df is a pandas DataFrame with features and 'target' column as the label\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# df = pd.read_csv('your_dataset.csv')\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Split data into training and test sets\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Classifiers\u001b[39;00m\n\u001b[0;32m     19\u001b[0m classifiers \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSVM\u001b[39m\u001b[38;5;124m\"\u001b[39m: SVC(),\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecision Tree\u001b[39m\u001b[38;5;124m\"\u001b[39m: DecisionTreeClassifier(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaive Bayes\u001b[39m\u001b[38;5;124m\"\u001b[39m: GaussianNB()\n\u001b[0;32m     25\u001b[0m }\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Example dataset (replace with your actual dataset)\n",
    "# Assume df is a pandas DataFrame with features and 'target' column as the label\n",
    "# df = pd.read_csv('your_dataset.csv')\n",
    "# X = df.drop(columns=['target'])\n",
    "# y = df['target']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Classifiers\n",
    "classifiers = {\n",
    "    \"SVM\": SVC(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Initialize an empty list to store results\n",
    "results_list = []\n",
    "\n",
    "# Train each classifier and compute the performance metrics\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Append the performance metrics for each classifier to the list\n",
    "    results_list.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average='weighted', zero_division=0),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    })\n",
    "\n",
    "# Convert the list of results into a DataFrame\n",
    "results_df = pd.DataFrame(results_list)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747be98-69a0-40ea-a774-c10ab8dfeb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
